{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SKIP THIS IF YOU WANT TO USE THE NON WEB INTERFACE (can only be done when notebook run locally)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tifffile not found, using skimage.externals\n",
      "Bokeh could not be loaded. Either it is not installed or you are not running within a notebook\n",
      "tifffile package not found, using skimage.external.tifffile\n",
      "numba not found\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    if __IPYTHON__:\n",
    "        # this is used for debugging purposes only. allows to reload classes when changed\n",
    "        get_ipython().magic(u'load_ext autoreload')\n",
    "        get_ipython().magic(u'autoreload 2')\n",
    "except NameError:       \n",
    "    print('Not IPYTHON')    \n",
    "    pass\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "from time import time\n",
    "from scipy.sparse import coo_matrix\n",
    "import psutil\n",
    "import glob\n",
    "import os\n",
    "import scipy\n",
    "from ipyparallel import Client\n",
    "#import matplotlib as mpl\n",
    "#mpl.use('TkAgg')\n",
    "\n",
    "import pylab as pl\n",
    "#pl.ion()\n",
    "\n",
    "import caiman as cm\n",
    "from caiman.components_evaluation import evaluate_components\n",
    "from caiman.utils.visualization import plot_contours,view_patches_bar,nb_plot_contour,nb_view_patches\n",
    "from caiman.base.rois import extract_binary_masks_blob\n",
    "import caiman.source_extraction.cnmf as cnmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"http://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"ba43a149-e1ee-4f3d-8778-5d6d5e2b8fc3\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(global) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (window._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    window._bokeh_onload_callbacks = [];\n",
       "    window._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "\n",
       "  \n",
       "  if (typeof (window._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    window._bokeh_timeout = Date.now() + 5000;\n",
       "    window._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    if (window.Bokeh !== undefined) {\n",
       "      var el = document.getElementById(\"ba43a149-e1ee-4f3d-8778-5d6d5e2b8fc3\");\n",
       "      el.textContent = \"BokehJS \" + Bokeh.version + \" successfully loaded.\";\n",
       "    } else if (Date.now() < window._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      window._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    }\n",
       "    finally {\n",
       "      delete window._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    window._bokeh_onload_callbacks.push(callback);\n",
       "    if (window._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    window._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        window._bokeh_is_loading--;\n",
       "        if (window._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"ba43a149-e1ee-4f3d-8778-5d6d5e2b8fc3\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid 'ba43a149-e1ee-4f3d-8778-5d6d5e2b8fc3' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.6.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.6.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "      document.getElementById(\"ba43a149-e1ee-4f3d-8778-5d6d5e2b8fc3\").textContent = \"BokehJS is loading...\";\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.6.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.6.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.6.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.6.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((window.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i](window.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < window._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!window._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      window._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"ba43a149-e1ee-4f3d-8778-5d6d5e2b8fc3\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (window._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(this));"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#import bokeh.plotting as bp\n",
    "import bokeh.plotting as bpl\n",
    "try:\n",
    "       from bokeh.io import vform, hplot\n",
    "except:\n",
    "       # newer version of bokeh does not use vform & hplot, instead uses column & row\n",
    "       from bokeh.layouts import column as vform\n",
    "       from bokeh.layouts import row as hplot\n",
    "from bokeh.models import CustomJS, ColumnDataSource, Slider\n",
    "from IPython.display import display, clear_output\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cmap\n",
    "import numpy as np\n",
    "\n",
    "bpl.output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Using the workload manager SLURM </h1> \n",
    "to have an extensive use of the machine. \n",
    "<p> This is to be used when working with a cluster of machines \n",
    "<img src=\"dev/kalfon/img/Dockerfile.gif\"/>\n",
    "</p><p>This will put dispatch and manage the workload gave by the algorithm : <img src=\"dev/kalfon/img/node.gif\" /></p>\n",
    "<p> learn more : <em> https://slurm.schedmd.com/overview.html </em> </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using 4 processes\n",
      "C was not existing, creating one\n",
      "Stopping  cluster to avoid unnencessary use of memory....\n",
      "Stopping cluster...\n",
      "NOT SLURM\n",
      "Waiting for cluster to stop....... done\n",
      "Starting cluster...Waiting for connection file: ~/.ipython/profile_default/security/ipcontroller-client.json\n",
      "......Using 4 processes\n"
     ]
    }
   ],
   "source": [
    "# frame rate in Hz\n",
    "final_frate=10 \n",
    "#backend='SLURM'\n",
    "backend='local'\n",
    "if backend == 'SLURM':\n",
    "    n_processes = np.int(os.environ.get('SLURM_NPROCS'))\n",
    "else:\n",
    "    n_processes = np.maximum(np.int(psutil.cpu_count()),1) # roughly number of cores on your machine minus 1\n",
    "print 'using ' + str(n_processes) + ' processes'\n",
    "#%% start cluster for efficient computation\n",
    "single_thread=False\n",
    "\n",
    "if single_thread:\n",
    "    dview=None\n",
    "else:    \n",
    "    try:\n",
    "        c.close()\n",
    "    except:\n",
    "        print 'C was not existing, creating one'\n",
    "    print \"Stopping  cluster to avoid unnencessary use of memory....\"\n",
    "    sys.stdout.flush()  \n",
    "    if backend == 'SLURM':\n",
    "        try:\n",
    "            cm.stop_server(is_slurm=True)\n",
    "        except:\n",
    "            print 'Nothing to stop'\n",
    "        slurm_script='/mnt/xfs1/home/agiovann/SOFTWARE/Constrained_NMF/SLURM/slurmStart.sh'\n",
    "        cm.start_server(slurm_script=slurm_script)\n",
    "        pdir, profile = os.environ['IPPPDIR'], os.environ['IPPPROFILE']\n",
    "        c = Client(ipython_dir=pdir, profile=profile)        \n",
    "    else:\n",
    "        cm.stop_server()\n",
    "        cm.start_server()        \n",
    "        c=Client()\n",
    "\n",
    "    print 'Using '+ str(len(c)) + ' processes'\n",
    "    dview=c[:len(c)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> We can see here that the number of processes are the number of core your computer possess. <br/> Your computer can be seen as a node that possess X cores </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> doing a F order mapping once again </h1>\n",
    "<p> see : demo_pypeline.ipynb </p>\n",
    "<img src=\"dev/kalfon/img/Fordermmap.png\" /> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('/Users/jeremie/CaImAn/example_movies/Yr0000_d1_60_d2_80_d3_1_order_C_frames_2000_.mmap', 2000)\n",
      "/Users/jeremie/CaImAn/example_movies/Yr_d1_60_d2_80_d3_1_order_C_frames_2000_.mmap\n",
      "Deleting big mov\n",
      "['/Users/jeremie/CaImAn/example_movies/demoMovie.tif']\n",
      "/Users/jeremie/CaImAn/example_movies/Yr_d1_60_d2_80_d3_1_order_C_frames_2000_.mmap\n",
      "\n",
      " we can see we are loading the file (line1) into a memorymapped object (line2)\n"
     ]
    }
   ],
   "source": [
    "#%% FOR LOADING ALL TIFF FILES IN A FILE AND SAVING THEM ON A SINGLE MEMORY MAPPABLE FILE\n",
    "fnames=[]\n",
    "base_folder='./example_movies/' # folder containing the demo files\n",
    "for file in glob.glob(os.path.join(base_folder,'*.tif')):\n",
    "    if file.endswith(\"ie.tif\"):\n",
    "        fnames.append(os.path.abspath(file))\n",
    "fnames.sort()\n",
    "  \n",
    "fnames=fnames\n",
    "downsample_factor=1 # use .2 or .1 if file is large and you want a quick answer\n",
    "final_frate=final_frate*downsample_factor\n",
    "idx_xy=None\n",
    "base_name='Yr'\n",
    "name_new=cm.save_memmap_each(fnames, dview=dview,base_name=base_name, resize_fact=(1, 1, downsample_factor), remove_init=0,idx_xy=idx_xy )\n",
    "name_new.sort()\n",
    "fname_new=cm.save_memmap_join(name_new,base_name='Yr', n_chunks=12, dview=dview)\n",
    "print fnames\n",
    "print fname_new\n",
    "print \"\\n we can see we are loading the file (line1) into a memorymapped object (line2)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> we are now visualizing one spatial chunks (its correlation throught time)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "Yr,dims,T=cm.load_memmap(fname_new)\n",
    "Y=np.reshape(Yr,dims+(T,),order='F')\n",
    "#%% visualize correlation image\n",
    "Cn = cm.local_correlations(Y)\n",
    "pl.imshow(Cn,cmap='gray') \n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Preprocessing of the datas and initialization of the components </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% parameters of experiment\n",
    "K=30 # number of neurons expected per patch\n",
    "gSig=[7,7] # expected half size of neurons\n",
    "merge_thresh=0.8 # merging threshold, max correlation allowed\n",
    "p=2 #order of the autoregressive system\n",
    "options = cnmf.utilities.CNMFSetParms(Y,n_processes,p=p,gSig=gSig,K=K,ssub=2,tsub=2, normalize_init=True)\n",
    "#%% PREPROCESS DATA AND INITIALIZE COMPONENTS\n",
    "t1 = time()\n",
    "Yr,sn,g,psx = cnmf.pre_processing.preprocess_data(Yr,dview=dview,**options['preprocess_params'])\n",
    "print time() - t1\n",
    "#%%\n",
    "t1 = time()\n",
    "Atmp, Ctmp, b_in, f_in, center=cnmf.initialization.initialize_components(Y, **options['init_params'])                                                    \n",
    "print time() - t1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> creating the initial cnmf values by refining the components </h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "refine_components=False\n",
    "if refine_components:\n",
    "    Ain,Cin = manually_refine_components(Y,options['init_params']['gSig'],coo_matrix(Atmp),Ctmp,Cn,thr=0.9)\n",
    "else:\n",
    "    Ain,Cin = Atmp, Ctmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pl.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p1=nb_plot_contour(Cn,Ain,dims[0],dims[1],thr=0.9,face_color=None, line_color='black',alpha=0.4,line_width=2)\n",
    "bpl.show(p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%% UPDATE SPATIAL COMPONENTS\n",
    "pl.close()\n",
    "t1 = time()\n",
    "A,b,Cin,f_in = cnmf.spatial.update_spatial_components(Yr, Cin, f_in, Ain, sn=sn, dview=dview,**options['spatial_params'])\n",
    "t_elSPATIAL = time() - t1\n",
    "print t_elSPATIAL \n",
    "#clear_output(wait=True)\n",
    "print('DONE!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pl.figure(num=None, figsize=(9, 7), dpi=100, facecolor='w', edgecolor='k')\n",
    "crd = plot_contours(A,Cn,thr=0.9)\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pl.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p1=nb_plot_contour(Cn,A.todense(),dims[0],dims[1],thr=0.9,face_color=None, line_color='black',alpha=0.4,line_width=2)\n",
    "bpl.show(p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pl.close()\n",
    "t1 = time()\n",
    "options['temporal_params']['p'] = 0 # set this to zero for fast updating without deconvolution\n",
    "C,A,b,f,S,bl,c1,neurons_sn,g,YrA = cnmf.temporal.update_temporal_components(Yr,A,b,Cin,f_in,bl=None,c1=None,sn=None,g=None,**options['temporal_params'])\n",
    "t_elTEMPORAL = time() - t1\n",
    "print t_elTEMPORAL  \n",
    "clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%% merge components corresponding to the same neuron\n",
    "t1 = time()\n",
    "A_m,C_m,nr_m,merged_ROIs,S_m,bl_m,c1_m,sn_m,g_m=cnmf.merging.merge_components(Yr,A,b,C,f,S,sn,options['temporal_params'], options['spatial_params'],dview=dview, bl=bl, c1=c1, sn=neurons_sn, g=g, thr=merge_thresh, mx=50, fast_merge = True)\n",
    "t_elMERGE = time() - t1\n",
    "print t_elMERGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#refine spatial and temporal components\n",
    "pl.close()\n",
    "t1 = time()\n",
    "A2,b2,C2,f = cnmf.spatial.update_spatial_components(Yr, C_m, f, A_m, sn=sn,dview=dview, **options['spatial_params'])\n",
    "options['temporal_params']['p'] = p # set it back to original value to perform full deconvolution\n",
    "C2,A2,b2,f2,S2,bl2,c12,neurons_sn2,g21,YrA = cnmf.temporal.update_temporal_components(Yr,A2,b2,C2,f,dview=dview, bl=None,c1=None,sn=None,g=None,**options['temporal_params'])\n",
    "clear_output(wait=True)\n",
    "print time() - t1 # 100 seconds\n",
    "print('DONE!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tB = np.minimum(-2,np.floor(-5./30*final_frate))\n",
    "tA = np.maximum(5,np.ceil(25./30*final_frate))\n",
    "Npeaks=10\n",
    "traces=C2+YrA\n",
    "#        traces_a=traces-scipy.ndimage.percentile_filter(traces,8,size=[1,np.shape(traces)[-1]/5])\n",
    "#        traces_b=np.diff(traces,axis=1)\n",
    "fitness_raw, fitness_delta, erfc_raw, erfc_delta, r_values, significant_samples = \\\n",
    "    evaluate_components(Y, traces, A, C, b, f, final_frate, remove_baseline=True,\n",
    "                                      N=5, robust_std=False, Athresh=0.1, Npeaks=Npeaks,  thresh_C=0.3)\n",
    "    \n",
    "idx_components_r=np.where(r_values>=.6)[0]\n",
    "idx_components_raw=np.where(fitness_raw<-60)[0]        \n",
    "idx_components_delta=np.where(fitness_delta<-20)[0]   \n",
    "\n",
    "\n",
    "min_radius=gSig[0]-2\n",
    "masks_ws,idx_blobs,idx_non_blobs=extract_binary_masks_blob(\n",
    "A2.tocsc(), min_radius, dims, num_std_threshold=1, \n",
    "minCircularity= 0.6, minInertiaRatio = 0.2,minConvexity =.8)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "idx_components=np.union1d(idx_components_r,idx_components_raw)\n",
    "idx_components=np.union1d(idx_components,idx_components_delta)  \n",
    "idx_blobs=np.intersect1d(idx_components,idx_blobs)   \n",
    "idx_components_bad=np.setdiff1d(range(len(traces)),idx_components)\n",
    "clear_output(wait=True)\n",
    "print(' ***** ')\n",
    "print len(traces)\n",
    "print(len(idx_components))\n",
    "print(len(idx_blobs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fg=pl.figure(figsize=(12,20))\n",
    "pl.subplot(1,3,1)\n",
    "crd = plot_contours(A2.tocsc()[:,idx_components],Cn,thr=0.9)\n",
    "pl.subplot(1,3,2)\n",
    "crd = plot_contours(A2.tocsc()[:,idx_blobs],Cn,thr=0.9)\n",
    "pl.subplot(1,3,3)\n",
    "crd = plot_contours(A2.tocsc()[:,idx_components_bad],Cn,thr=0.9)\n",
    "print dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p2=nb_plot_contour(Cn,A2.tocsc()[:,idx_components].todense(),dims[0],dims[1],thr=0.9,face_color='purple', line_color='black',alpha=0.3,line_width=2)\n",
    "bpl.show(p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "traces_fluo=nb_view_patches(Yr,A2.tocsc()[:,idx_components].todense(),C[idx_components],b2,f2,dims[0],dims[1],thr = 0.9,image_neurons=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%% STOP CLUSTER\n",
    "cm.stop_server()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
