{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare ground truth built by matching with the results of CNMF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Up the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from skimage.util import montage\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "import caiman as cm\n",
    "from caiman.utils.utils import download_demo\n",
    "from caiman.base.rois import com, extract_binary_masks_blob\n",
    "from caiman.utils.visualization import plot_contours, view_patches_bar\n",
    "from caiman.source_extraction.cnmf import cnmf as cnmf\n",
    "from caiman.motion_correction import MotionCorrect, tile_and_correct, motion_correction_piecewise \n",
    "from caiman.components_evaluation import estimate_components_quality, evaluate_components\n",
    "from caiman.tests.comparison import comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading up the Ground Truth Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [{'fname': '/mnt/ceph/data/neuro/caiman/labeling/neurofinder.03.00.test/images/final_map/Yr_d1_498_d2_467_d3_1_order_C_frames_2250_.mmap', \n",
    "              'gSig': [8, 8]},\n",
    "          {'fname': '/mnt/ceph/data/neuro/caiman/labeling/neurofinder.04.00.test/images/final_mapYr_d1_512_d2_512_d3_1_order_C_frames_3000_.mmap',\n",
    "              'gSig': [5, 5]},\n",
    "          {'fname': '/mnt/ceph/data/neuro/caiman/labeling/neurofinder.02.00/images/final_map/Yr_d1_512_d2_512_d3_1_order_C_frames_8000_.mmap',\n",
    "              'gSig': [5, 5]},\n",
    "          {'fname': '/mnt/ceph/data/neuro/caiman/labeling/yuste.Single_150u/images/final_map/Yr_d1_200_d2_256_d3_1_order_C_frames_3000_.mmap',\n",
    "              'gSig': [5, 5]},\n",
    "          {'fname': '/mnt/ceph/data/neuro/caiman/labeling/neurofinder.00.00/images/final_map/Yr_d1_512_d2_512_d3_1_order_C_frames_2936_.mmap',\n",
    "              'gSig': [6, 6]},\n",
    "          {'fname': '/mnt/ceph/data/neuro/caiman/labeling/neurofinder.01.01/images/final_map/Yr_d1_512_d2_512_d3_1_order_C_frames_1825_.mmap',\n",
    "              'gSig': [6, 6]},\n",
    "          {'fname': '/mnt/ceph/data/neuro/caiman/labeling/k53_20160530/images/final_map/Yr_d1_512_d2_512_d3_1_order_C_frames_116043_.mmap',\n",
    "               'gSig': [6, 6]},\n",
    "          {'fname': '/mnt/ceph/data/neuro/caiman/labeling/J115_2015-12-09_L01_ELS/images/final_map/Yr_d1_463_d2_472_d3_1_order_C_frames_90000_.mmap',\n",
    "              'gSig': [7, 7]},\n",
    "          # {'fname': '/mnt/ceph/data/neuro/caiman/labeling/J123_2015-11-20_L01_0/images/final_map/Yr_d1_458_d2_477_d3_1_order_C_frames_41000_.mmap',\n",
    "          #    'gSig': [12, 12]}, \n",
    "          {'fname': '/mnt/ceph/data/neuro/caiman/labeling/Jan-AMG_exp3_001/images/final_map/Yr_d1_512_d2_512_d3_1_order_C_frames_115897_.mmap',\n",
    "              'gSig': [7, 7]},\n",
    "          {'fname': '/mnt/ceph/data/neuro/caiman/labeling/J123_2015-11-20_L01_0/images/final_map/Yr_d1_458_d2_477_d3_1_order_C_frames_41000_.mmap',\n",
    "              'gSig': [12, 12]}, #moved around -> check the old document\n",
    "          {'fname': '', 'gSig': []}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data and Analysis using match_masks.npz file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/ceph/data/neuro/caiman/labeling/neurofinder.03.00.test/images/final_map/Yr_d1_498_d2_467_d3_1_order_C_frames_2250_.mmap\n",
      "KeysView(NpzFile '/mnt/ceph/data/neuro/caiman/labeling/neurofinder.03.00.test/images/final_map/Yr_d1_498_d2_467_d3_1_order_C_frames_2250_.match_masks.npz' with keys: fn_gt, Cn, idx_components_gt, d1, A_gt...)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Object arrays cannot be loaded when allow_pickle=False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39mload(gt_file, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatin1\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m ld:\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28mprint\u001b[39m(ld\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m---> 19\u001b[0m     \u001b[38;5;28;43mlocals\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mld\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     A_gt \u001b[38;5;241m=\u001b[39m scipy\u001b[38;5;241m.\u001b[39msparse\u001b[38;5;241m.\u001b[39mcoo_matrix(A_gt[()])\n\u001b[1;32m     21\u001b[0m     dims \u001b[38;5;241m=\u001b[39m (d1, d2)\n",
      "File \u001b[0;32m~/miniforge3/envs/caiman_pytorch/lib/python3.12/site-packages/numpy/lib/npyio.py:256\u001b[0m, in \u001b[0;36mNpzFile.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m magic \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mMAGIC_PREFIX:\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28mbytes\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mzip\u001b[38;5;241m.\u001b[39mopen(key)\n\u001b[0;32m--> 256\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_array\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mbytes\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mallow_pickle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mmax_header_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_header_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mzip\u001b[38;5;241m.\u001b[39mread(key)\n",
      "File \u001b[0;32m~/miniforge3/envs/caiman_pytorch/lib/python3.12/site-packages/numpy/lib/format.py:795\u001b[0m, in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs, max_header_size)\u001b[0m\n\u001b[1;32m    792\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype\u001b[38;5;241m.\u001b[39mhasobject:\n\u001b[1;32m    793\u001b[0m     \u001b[38;5;66;03m# The array contained Python objects. We need to unpickle the data.\u001b[39;00m\n\u001b[1;32m    794\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_pickle:\n\u001b[0;32m--> 795\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mObject arrays cannot be loaded when \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    796\u001b[0m                          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_pickle=False\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    797\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pickle_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    798\u001b[0m         pickle_kwargs \u001b[38;5;241m=\u001b[39m {}\n",
      "\u001b[0;31mValueError\u001b[0m: Object arrays cannot be loaded when allow_pickle=False"
     ]
    }
   ],
   "source": [
    "for dc in inputs[:]:\n",
    "    fname = dc['fname']\n",
    "    print(fname)\n",
    "    gSig = dc['gSig']\n",
    "    \n",
    "    # with np.load(os.path.join(os.path.split(fname)[0], os.path.split(fname)[1][:-4] + 'results_analysis.npz'), encoding='latin1') as ld:\n",
    "    #    print(ld.keys())\n",
    "    #    locals().update(ld)\n",
    "    #    dims_off = d1, d2\n",
    "    #    A = scipy.sparse.coo_matrix(A[()])\n",
    "    #    dims = (d1, d2)\n",
    "\n",
    "    gt_file = os.path.join(os.path.split(fname)[0], os.path.split(fname)[1][:-4] \n",
    "                           + 'match_masks.npz') #for match_masks_pytorch.npz -> rerun 1. \n",
    "    \n",
    "    with np.load(gt_file, encoding='latin1') as ld:\n",
    "        print(ld.keys())\n",
    "        locals().update(ld)\n",
    "        A_gt = scipy.sparse.coo_matrix(A_gt[()])\n",
    "        dims = (d1, d2)\n",
    "\n",
    "    pl.figure()\n",
    "    dist_A = (normalize(A_gt.tocsc()[:, idx_components_gt], axis=0).T.dot(\n",
    "        normalize(A.tocsc()[:, :], axis=0))).toarray()\n",
    "    dist_C = normalize(C_gt[idx_components_gt], axis=1).dot(\n",
    "        normalize(C[:], axis=1).T)\n",
    "    dist_A = dist_A * (dist_A > 0)\n",
    "\n",
    "    pl.figure(figsize=(30, 20))\n",
    "    tp_gt, tp_comp, fn_gt, fp_comp, performance_cons_off = cm.base.rois.nf_match_neurons_in_binary_masks(A_gt.toarray()[:, idx_components_gt].reshape([dims[0], dims[1], -1], order='F').transpose([2, 0, 1]),\n",
    "                                                                                                         A.toarray()[:, :].reshape([dims[0], dims[1], -1], order='F').transpose([2, 0, 1]), thresh_cost=.7, min_dist=10,\n",
    "                                                                                                         print_assignment=False, plot_results=False, Cn=Cn, labels=['GT', 'Offline'], D=[1 - dist_A * (dist_C > .8)])\n",
    "    pl.rcParams['pdf.fonttype'] = 42\n",
    "    font = {'family': 'Myriad Pro',\n",
    "            'weight': 'regular',\n",
    "            'size': 20}\n",
    "    pl.rc('font', **font)\n",
    "    idx_final = tp_comp[np.where(dist_A[tp_gt, tp_comp] > 0.7)[0]]\n",
    "    np.savez(os.path.join(os.path.split(fname)[0], os.path.split(fname)[1][:-4] + '_training_set_minions.npz'), fname_new=fname,\n",
    "             A_seeded=A_gt.tocsc()[\n",
    "        :, idx_components_gt], C_seeded=C_gt[idx_components_gt], YrA_seeded=YrA_gt[idx_components_gt],\n",
    "        A_matched=A.tocsc()[\n",
    "        :, idx_final], C_matched=C[idx_final], YrA_matched=YrA[idx_final],\n",
    "        A_unmatched=A_gt.tocsc()[\n",
    "        :, fn_gt], C_unmatched=C_gt[fn_gt], YrA_unmatched=YrA_gt[fn_gt],\n",
    "        A_negative=A.tocsc()[\n",
    "        :, fp_comp], C_negative=C[fp_comp], YrA_negative=YrA[fp_comp],\n",
    "        r_values=r_values, fitness_delta=fitness_delta, fitness_raw=fitness_raw, Cn=Cn, dims=dims, gSig=gSig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain Training Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/mnt/ceph/data/neuro/caiman/labeling/k53_20160530/images/final_map/Yr_d1_512_d2_512_d3_1_order_C_frames_116043_._training_set_minions.npz', '/mnt/ceph/data/neuro/caiman/labeling/neurofinder.00.00/images/final_map/Yr_d1_512_d2_512_d3_1_order_C_frames_2936_._training_set_minions.npz', '/mnt/ceph/data/neuro/caiman/labeling/Jan-AMG_exp3_001/images/final_map/Yr_d1_512_d2_512_d3_1_order_C_frames_115897_._training_set_minions.npz', '/mnt/ceph/data/neuro/caiman/labeling/yuste.Single_150u/images/final_map/Yr_d1_200_d2_256_d3_1_order_C_frames_3000_._training_set_minions.npz', '/mnt/ceph/data/neuro/caiman/labeling/neurofinder.03.00.test/images/final_map/Yr_d1_498_d2_467_d3_1_order_C_frames_2250_._training_set_minions.npz', '/mnt/ceph/data/neuro/caiman/labeling/neurofinder.04.00.test/images/final_map/Yr_d1_512_d2_512_d3_1_order_C_frames_3000_._training_set_minions.npz', '/mnt/ceph/data/neuro/caiman/labeling/neurofinder.02.00/images/final_map/Yr_d1_512_d2_512_d3_1_order_C_frames_8000_._training_set_minions.npz', '/mnt/ceph/data/neuro/caiman/labeling/neurofinder.01.01/images/final_map/Yr_d1_512_d2_512_d3_1_order_C_frames_1825_._training_set_minions.npz', '/mnt/ceph/data/neuro/caiman/labeling/J115_2015-12-09_L01_ELS/images/final_map/Yr_d1_463_d2_472_d3_1_order_C_frames_90000_._training_set_minions.npz', '/mnt/ceph/data/neuro/caiman/labeling/J123_2015-11-20_L01_0/images/final_map/Yr_d1_458_d2_477_d3_1_order_C_frames_41000_._training_set_minions.npz']\n"
     ]
    }
   ],
   "source": [
    "training_files = [os.path.join(dp, f) for dp, dn, filenames in os.walk('/mnt/ceph/data/neuro/caiman/') for f in filenames if 'set_minions.npz' in f]\n",
    "print(training_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_size = 50\n",
    "half_crop = crop_size // 2\n",
    "id_file = 0\n",
    "reference_gSig_neuron = 5\n",
    "\n",
    "all_masks_gt = []\n",
    "labels_gt = []\n",
    "traces_gt = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KeysView(NpzFile '/mnt/ceph/data/neuro/caiman/labeling/k53_20160530/images/final_map/Yr_d1_512_d2_512_d3_1_order_C_frames_116043_._training_set_minions.npz' with keys: fname_new, A_seeded, C_seeded, YrA_seeded, A_matched...)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Object arrays cannot be loaded when allow_pickle=False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39mload(fl) \u001b[38;5;28;01mas\u001b[39;00m ld:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(ld\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28;43mlocals\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mld\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     zoom \u001b[38;5;241m=\u001b[39m reference_gSig_neuron \u001b[38;5;241m/\u001b[39m gSig[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      7\u001b[0m     fname_new \u001b[38;5;241m=\u001b[39m fname_new[()]\n",
      "File \u001b[0;32m~/miniforge3/envs/caiman_pytorch/lib/python3.12/site-packages/numpy/lib/npyio.py:256\u001b[0m, in \u001b[0;36mNpzFile.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m magic \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mMAGIC_PREFIX:\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28mbytes\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mzip\u001b[38;5;241m.\u001b[39mopen(key)\n\u001b[0;32m--> 256\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_array\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mbytes\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mallow_pickle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mmax_header_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_header_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mzip\u001b[38;5;241m.\u001b[39mread(key)\n",
      "File \u001b[0;32m~/miniforge3/envs/caiman_pytorch/lib/python3.12/site-packages/numpy/lib/format.py:795\u001b[0m, in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs, max_header_size)\u001b[0m\n\u001b[1;32m    792\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype\u001b[38;5;241m.\u001b[39mhasobject:\n\u001b[1;32m    793\u001b[0m     \u001b[38;5;66;03m# The array contained Python objects. We need to unpickle the data.\u001b[39;00m\n\u001b[1;32m    794\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_pickle:\n\u001b[0;32m--> 795\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mObject arrays cannot be loaded when \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    796\u001b[0m                          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_pickle=False\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    797\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pickle_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    798\u001b[0m         pickle_kwargs \u001b[38;5;241m=\u001b[39m {}\n",
      "\u001b[0;31mValueError\u001b[0m: Object arrays cannot be loaded when allow_pickle=False"
     ]
    }
   ],
   "source": [
    "for fl in training_files:\n",
    "\n",
    "    with np.load(fl) as ld:\n",
    "        print(ld.keys())\n",
    "        locals().update(ld)\n",
    "        zoom = reference_gSig_neuron / gSig[0]\n",
    "        fname_new = fname_new[()]\n",
    "        name_base = os.path.split(fname_new)[-1][:-5]\n",
    "\n",
    "        if 'sparse' in str(type(A_matched[()])):\n",
    "            A_matched = A_matched[()].toarray()\n",
    "            A_unmatched = A_unmatched[()].toarray()\n",
    "            A_negative = A_negative[()].toarray()\n",
    "\n",
    "        A_matched = normalize(A_matched, axis=0)\n",
    "        A_unmatched = normalize(A_unmatched, axis=0)\n",
    "        A_negative = normalize(A_negative, axis=0)\n",
    "        \n",
    "        masks_gt = np.concatenate([A_matched.reshape(tuple(dims) + (-1,), order='F').transpose([2, 0, 1]), A_unmatched.reshape(tuple(\n",
    "            dims) + (-1,), order='F').transpose([2, 0, 1]), A_negative.reshape(tuple(dims) + (-1,), order='F').transpose([2, 0, 1])], axis=0)\n",
    "        labels_gt = np.concatenate([labels_gt, np.ones(\n",
    "            A_matched.shape[-1]), np.ones(A_unmatched.shape[-1]), np.zeros(A_negative.shape[-1])])\n",
    "        traces_gt = traces_gt + list(YrA_matched + C_matched) + list(\n",
    "            C_unmatched + YrA_unmatched) + list(C_negative + YrA_negative)\n",
    "\n",
    "        coms = [scipy.ndimage.center_of_mass(mm) for mm in masks_gt]\n",
    "        coms = np.maximum(coms, half_crop)\n",
    "        coms = np.array([np.minimum(cm, dims - half_crop) for cm in coms])\n",
    "\n",
    "        count_neuro = 0\n",
    "        for com, img in zip(coms, masks_gt):\n",
    "\n",
    "            com = com.astype(int)\n",
    "            # Crop from x, y, w, h -> 100, 200, 300, 400\n",
    "            crop_img = img[com[0] - half_crop:com[0] + half_crop,\n",
    "                           com[1] - half_crop:com[1] + half_crop].copy()\n",
    "\n",
    "            borders = np.array(crop_img.shape)\n",
    "            img_tmp = np.zeros_like(crop_img)\n",
    "            crop_img = cv2.resize(crop_img, dsize=None, fx=zoom, fy=zoom)\n",
    "            \n",
    "            deltaw = (half_crop * 2 - crop_img.shape[0]) // 2\n",
    "            deltah = (half_crop * 2 - crop_img.shape[1]) // 2\n",
    "            img_tmp[deltaw:deltaw + crop_img.shape[0],\n",
    "                    deltah:deltah + crop_img.shape[1]] = crop_img\n",
    "            crop_img = img_tmp\n",
    "            crop_img = crop_img / np.linalg.norm(crop_img)\n",
    "            all_masks_gt.append(crop_img[np.newaxis, :, :, np.newaxis])\n",
    "            augment_test = False\n",
    "            cv2.imshow(\"cropped\", cv2.resize(crop_img, (480, 480)) * 10)\n",
    "            cv2.waitKey(1)\n",
    "            if augment_test:\n",
    "                datagen = ImageDataGenerator(\n",
    "                    shear_range=0.3,\n",
    "                    rotation_range=360,\n",
    "                    width_shift_range=0.2,\n",
    "                    height_shift_range=0.2,\n",
    "                    zoom_range=[.5, 2],\n",
    "                    horizontal_flip=True,\n",
    "                    vertical_flip=True,\n",
    "                    random_mult_range=[.25, 2]\n",
    "                )\n",
    "                \n",
    "                count_neuro += 1\n",
    "                for x_batch, y_batch in datagen.flow(np.repeat(crop_img[np.newaxis, :, :], 10, 0)[:, :, :, None], [1, 1, 1, 1, 1, 1, 1, 1, 0, 0], batch_size=10):\n",
    "                    print(y_batch)\n",
    "                    for b_img in x_batch:\n",
    "                        cv2.imshow(\"cropped\", cv2.resize(\n",
    "                            b_img.squeeze(), (480, 480)) * 10)\n",
    "                        cv2.waitKey(300)\n",
    "                        count_neuro += 1\n",
    "                        print(count_neuro)\n",
    "                    break\n",
    "\n",
    "        id_file += 1\n",
    "\n",
    "all_masks_gt = np.vstack(all_masks_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cm\u001b[38;5;241m.\u001b[39mmovie(np\u001b[38;5;241m.\u001b[39msqueeze(\u001b[43mall_masks_gt\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlabels_gt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m))\u001b[38;5;241m.\u001b[39mplay(\n\u001b[1;32m      2\u001b[0m     gain\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3.\u001b[39m, magnification\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "cm.movie(np.squeeze(all_masks_gt[labels_gt == 0])).play(\n",
    "    gain=3., magnification=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('ground_truth_components.npz',\n",
    "         all_masks_gt=all_masks_gt, labels_gt=labels_gt, traces_gt=traces_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grouper(n, iterable, fillvalue=None):\n",
    "    \"grouper(3, 'ABCDEFG', 'x') --> ABC DEF Gxx\"\n",
    "    args = [iter(iterable)] * n\n",
    "    return itertools.zip_longest(*args, fillvalue=fillvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curate Once More. Remove Wrong Negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2502183/2601765623.py:1: DeprecationWarning: Calling nonzero on 0d arrays is deprecated, as it behaves surprisingly. Use `atleast_1d(cond).nonzero()` if the old behavior was intended. If the context of this warning is of the form `arr[nonzero(cond)]`, just use `arr[cond]`.\n",
      "  negatives = np.where(labels_gt == 1)[0]\n"
     ]
    }
   ],
   "source": [
    "negatives = np.where(labels_gt == 1)[0]\n",
    "wrong = []\n",
    "count = 0\n",
    "for a in grouper(50, negatives):\n",
    "    print(np.max(a))\n",
    "    print(count)\n",
    "    a = np.array(a)[np.array(a) > 0].astype(int)\n",
    "    count += 1\n",
    "    img_mont_ = all_masks_gt[np.array(a)].squeeze()\n",
    "    shps_img = img_mont_.shape\n",
    "    img_mont = montage2d(img_mont_)\n",
    "    shps_img_mont = np.array(img_mont.shape) // 50\n",
    "    plt.figure(figsize=(20, 30))\n",
    "    plt.imshow(img_mont)\n",
    "    inp = pl.ginput(n=0, timeout=-100000)\n",
    "    imgs_to_exclude = []\n",
    "    inp = np.ceil(np.array(inp) / 50).astype(int) - 1\n",
    "    if len(inp) > 0:\n",
    "\n",
    "        imgs_to_exclude = img_mont_[np.ravel_multi_index(\n",
    "            [inp[:, 1], inp[:, 0]], shps_img_mont)]\n",
    "        wrong.append(np.array(a)[np.ravel_multi_index(\n",
    "            [inp[:, 1], inp[:, 0]], shps_img_mont)])\n",
    "    np.save('temp_label_pos_minions.npy', wrong)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "need at least one array to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(montage(all_masks_gt[\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwrong\u001b[49m\u001b[43m)\u001b[49m]\u001b[38;5;241m.\u001b[39msqueeze()))\n",
      "\u001b[0;31mValueError\u001b[0m: need at least one array to concatenate"
     ]
    }
   ],
   "source": [
    "plt.imshow(montage(all_masks_gt[np.concatenate(wrong)].squeeze()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'temp_label_pos_minions.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m lab_pos_wrong \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtemp_label_pos_minions.npy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m lab_neg_wrong \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtemp_label_neg_plus_minions.npy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m labels_gt_cur \u001b[38;5;241m=\u001b[39m labels_gt\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[0;32m~/miniforge3/envs/caiman_pytorch/lib/python3.12/site-packages/numpy/lib/npyio.py:427\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    425\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 427\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    428\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'temp_label_pos_minions.npy'"
     ]
    }
   ],
   "source": [
    "lab_pos_wrong = np.load('temp_label_pos_minions.npy')\n",
    "lab_neg_wrong = np.load('temp_label_neg_plus_minions.npy')\n",
    "\n",
    "labels_gt_cur = labels_gt.copy()\n",
    "labels_gt_cur[np.concatenate(lab_pos_wrong)] = 0\n",
    "labels_gt_cur[np.concatenate(lab_neg_wrong)] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the file to train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'labels_gt_cur' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m np\u001b[38;5;241m.\u001b[39msavez(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mground_truth_comoponents_curated.npz\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m----> 2\u001b[0m          all_masks_gt\u001b[38;5;241m=\u001b[39mall_masks_gt, labels_gt_cur\u001b[38;5;241m=\u001b[39m\u001b[43mlabels_gt_cur\u001b[49m)\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(montage2d(all_masks_gt[labels_gt_cur \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msqueeze()))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'labels_gt_cur' is not defined"
     ]
    }
   ],
   "source": [
    "np.savez('ground_truth_comoponents_curated.npz',\n",
    "         all_masks_gt=all_masks_gt, labels_gt_cur=labels_gt_cur)\n",
    "\n",
    "plt.imshow(montage2d(all_masks_gt[labels_gt_cur == 0].squeeze()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "caiman_pytorch",
   "language": "python",
   "name": "caiman_pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
