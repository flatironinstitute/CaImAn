{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Nov 21 15:53:15 2016\n",
    "\n",
    "@author: agiovann\n",
    "\"\"\"\n",
    "%matplotlib\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from builtins import zip\n",
    "from builtins import str\n",
    "from builtins import map\n",
    "from builtins import range\n",
    "from past.utils import old_div\n",
    "import cv2\n",
    "try:\n",
    "    cv2.setNumThreads(1)\n",
    "except:\n",
    "    print('Open CV is naturally single threaded')\n",
    "\n",
    "try:\n",
    "    if __IPYTHON__:\n",
    "        print((1))\n",
    "        # this is used for debugging purposes only. allows to reload classes\n",
    "        # when changed\n",
    "        get_ipython().magic('load_ext autoreload')\n",
    "        get_ipython().magic('autoreload 2')\n",
    "except NameError:\n",
    "    print('Not IPYTHON')\n",
    "    pass\n",
    "#%%\n",
    "import caiman as cm\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "import pylab as pl\n",
    "import psutil\n",
    "import sys\n",
    "from ipyparallel import Client\n",
    "from skimage.external.tifffile import TiffFile\n",
    "import scipy\n",
    "#%%\n",
    "from caiman.motion_correction import tile_and_correct, motion_correction_piecewise\n",
    "from caiman.source_extraction.cnmf import cnmf as cnmf\n",
    "from caiman.motion_correction import MotionCorrect\n",
    "from caiman.components_evaluation import evaluate_components\n",
    "from caiman.utils.visualization import plot_contours, view_patches_bar\n",
    "from caiman.base.rois import extract_binary_masks_blob\n",
    "from caiman.utils.utils import download_demo\n",
    "\n",
    "\n",
    "#%%\n",
    "#m = cm.load('example_movies/demoMovie.tif')\n",
    "#\n",
    "#cm.concatenate([m.resize(1,1,.2),m.resize(1,1,.2)],axis =1).play(fr =20, gain = 3.,magnification =3)\n",
    "#%% set parameters and create template by RIGID MOTION CORRECTION\n",
    "params_movie = {'fname': 'example_movies/demoSue2x.tif',\n",
    "                'niter_rig': 1,\n",
    "                'max_shifts': (6, 6),  # maximum allow rigid shift\n",
    "                'splits_rig': 56,  # for parallelization split the movies in  num_splits chuncks across time\n",
    "                # if none all the splits are processed and the movie is saved\n",
    "                'num_splits_to_process_rig': None,\n",
    "                # intervals at which patches are laid out for motion correction\n",
    "                'strides': (48, 48),\n",
    "                # overlap between pathes (size of patch strides+overlaps)\n",
    "                'overlaps': (24, 24),\n",
    "                'splits_els': 56,  # for parallelization split the movies in  num_splits chuncks across time\n",
    "                # if none all the splits are processed and the movie is saved\n",
    "                'num_splits_to_process_els': [28, None],\n",
    "                'upsample_factor_grid': 4,  # upsample factor to avoid smearing when merging patches\n",
    "                # maximum deviation allowed for patch with respect to rigid\n",
    "                # shift\n",
    "                'max_deviation_rigid': 3,\n",
    "                'p': 1,  # order of the autoregressive system\n",
    "                'merge_thresh': 0.8,  # merging threshold, max correlation allowed\n",
    "                'rf': 15,  # half-size of the patches in pixels. rf=25, patches are 50x50\n",
    "                'stride_cnmf': 6,  # amounpl.it of overlap between the patches in pixels\n",
    "                'K': 4,  # number of components per patch\n",
    "                # if dendritic. In this case you need to set init_method to\n",
    "                # sparse_nmf\n",
    "                'is_dendrites': False,\n",
    "                'init_method': 'greedy_roi',\n",
    "                'gSig': [4, 4],  # expected half size of neurons\n",
    "                'alpha_snmf': None,  # this controls sparsity\n",
    "                'final_frate': 30\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%% parameters from dictionary\n",
    "fname = params_movie['fname']\n",
    "niter_rig = params_movie['niter_rig']\n",
    "# maximum allow rigid shift\n",
    "max_shifts = params_movie['max_shifts']  \n",
    "# for parallelization split the movies in  num_splits chuncks across time\n",
    "splits_rig = params_movie['splits_rig']  \n",
    "# if none all the splits are processed and the movie is saved\n",
    "num_splits_to_process_rig = params_movie['num_splits_to_process_rig']\n",
    "# intervals at which patches are laid out for motion correction\n",
    "strides = params_movie['strides']\n",
    "# overlap between pathes (size of patch strides+overlaps)\n",
    "overlaps = params_movie['overlaps']\n",
    "# for parallelization split the movies in  num_splits chuncks across time\n",
    "splits_els = params_movie['splits_els'] \n",
    "# if none all the splits are processed and the movie is saved\n",
    "num_splits_to_process_els = params_movie['num_splits_to_process_els']\n",
    "# upsample factor to avoid smearing when merging patches\n",
    "upsample_factor_grid = params_movie['upsample_factor_grid'] \n",
    "# maximum deviation allowed for patch with respect to rigid\n",
    "# shift\n",
    "max_deviation_rigid = params_movie['max_deviation_rigid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%% download movie if not there\n",
    "if fname == 'example_movies/demoSue2x.tif':\n",
    "    download_demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%% load movie (in memory!)\n",
    "m_orig = cm.load(fname)\n",
    "#%% play movie\n",
    "downsample_ratio = .2\n",
    "offset_mov = -np.min(m_orig[:100])\n",
    "m_orig.resize(1, 1, downsample_ratio).play(\n",
    "    gain=10, offset = offset_mov, fr=30, magnification=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%% motion correction rigid\n",
    "c, dview, n_processes = cm.cluster.setup_cluster(\n",
    "    backend='local', n_processes=None, single_thread=False)\n",
    "#%%\n",
    "# movie must be mostly positive for this to work\n",
    "min_mov = cm.load(fname, subindices=range(400)).min()\n",
    "\n",
    "mc = MotionCorrect(fname, min_mov,\n",
    "                   dview=dview, max_shifts=max_shifts, niter_rig=niter_rig, splits_rig=splits_rig, \n",
    "                   num_splits_to_process_rig=num_splits_to_process_rig, \n",
    "                strides= strides, overlaps= overlaps, splits_els=splits_els,\n",
    "                num_splits_to_process_els=num_splits_to_process_els, \n",
    "                upsample_factor_grid=upsample_factor_grid, max_deviation_rigid=max_deviation_rigid, \n",
    "                shifts_opencv = True, nonneg_movie = True)\n",
    "#%%\n",
    "mc.motion_correct_rigid(save_movie=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load motion corrected movie\n",
    "m_rig = cm.load(mc.fname_tot_rig)\n",
    "pl.imshow(mc.total_template_rig, cmap = 'gray')\n",
    "#%% visualize templates\n",
    "cm.movie(np.array(mc.templates_rig)).play(\n",
    "    fr=10, gain=5, magnification=2, offset=offset_mov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%% plot rigid shifts\n",
    "pl.close()\n",
    "pl.plot(mc.shifts_rig)\n",
    "pl.legend(['x shifts','y shifts'])\n",
    "pl.xlabel('frames')\n",
    "pl.ylabel('pixels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%% inspect movie\n",
    "bord_px_rig = np.ceil(np.max(mc.shifts_rig)).astype(np.int)\n",
    "downsample_ratio = .2\n",
    "m_rig.resize(1, 1, downsample_ratio).play(\n",
    "    gain=10, offset = offset_mov*.25, fr=30, magnification=2,bord_px = bord_px_rig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%% motion correct piecewise rigid\n",
    "mc.motion_correct_pwrigid(save_movie=True, template=mc.total_template_rig, show_template = True)\n",
    "m_els = cm.load(mc.fname_tot_els)\n",
    "pl.imshow(mc.total_template_els, cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%% visualize elastic shifts\n",
    "pl.close()\n",
    "pl.subplot(2, 1, 1)\n",
    "pl.plot(mc.x_shifts_els)\n",
    "pl.ylabel('x shifts (pixels)')\n",
    "pl.subplot(2, 1, 2)\n",
    "pl.plot(mc.y_shifts_els)\n",
    "pl.ylabel('y_shifts (pixels)')\n",
    "pl.xlabel('frames')\n",
    "#%% compute borders to exclude\n",
    "bord_px_els = np.ceil(np.maximum(np.max(np.abs(mc.x_shifts_els)),\n",
    "                                 np.max(np.abs(mc.y_shifts_els)))).astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check movie\n",
    "downsample_ratio = .2\n",
    "m_els.resize(1, 1, downsample_ratio).play(\n",
    "    gain=10, offset = 0, fr=30, magnification=2,bord_px = bord_px_els)\n",
    "# compare with original and rigid corrected movies\n",
    "downsample_factor = .2\n",
    "cm.concatenate([m_orig.resize(1, 1, downsample_factor)+offset_mov, m_rig.resize(1, 1, downsample_factor), m_els.resize(\n",
    "    1, 1, downsample_factor)], axis=2).play(fr=60, gain=15, magnification=2, offset=0)\n",
    "#%% local correlation\n",
    "pl.imshow(m_els.local_correlations(eight_neighbours=True, swap_dim=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#% compute metrics for the results (TAKES TIME!!)\n",
    "final_size = np.subtract(mc.total_template_els.shape, 2 * bord_px_els)\n",
    "winsize = 100\n",
    "swap_dim = False\n",
    "resize_fact_flow = .2\n",
    "tmpl, correlations, flows_orig, norms, smoothness = cm.motion_correction.compute_metrics_motion_correction(\n",
    "    mc.fname_tot_els, final_size[0], final_size[1], swap_dim, winsize=winsize, play_flow=False, resize_fact_flow=resize_fact_flow)\n",
    "tmpl, correlations, flows_orig, norms, smoothness = cm.motion_correction.compute_metrics_motion_correction(\n",
    "    mc.fname_tot_rig, final_size[0], final_size[1], swap_dim, winsize=winsize, play_flow=False, resize_fact_flow=resize_fact_flow)\n",
    "tmpl, correlations, flows_orig, norms, smoothness = cm.motion_correction.compute_metrics_motion_correction(\n",
    "    fname, final_size[0], final_size[1], swap_dim, winsize=winsize, play_flow=False, resize_fact_flow=resize_fact_flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%% plot the results of metrics\n",
    "fls = [mc.fname_tot_els[:-4] + '_metrics.npz', mc.fname_tot_rig[:-4] +\n",
    "       '_metrics.npz', mc.fname[:-4] + '_metrics.npz']\n",
    "#%%\n",
    "for cnt, fl, metr in zip(range(len(fls)),fls,['pw_rigid','rigid','raw']):\n",
    "    with np.load(fl) as ld:\n",
    "        print(ld.keys())\n",
    "#        pl.figure()\n",
    "        print(fl)\n",
    "        print(str(np.mean(ld['norms'])) + '+/-' + str(np.std(ld['norms'])) +\n",
    "              ' ; ' + str(ld['smoothness']) + ' ; ' + str(ld['smoothness_corr']))\n",
    "        if True:\n",
    "            pl.subplot(len(fls), 4, 1 + 4 * cnt)\n",
    "            pl.ylabel(metr)\n",
    "            try:\n",
    "                mean_img = np.mean(\n",
    "                    cm.load(fl[:-12] + 'mmap'), 0)[12:-12, 12:-12]\n",
    "            except:\n",
    "                try:\n",
    "                    mean_img = np.mean(\n",
    "                        cm.load(fl[:-12] + '.tif'), 0)[12:-12, 12:-12]\n",
    "                except:\n",
    "                    mean_img = np.mean(\n",
    "                        cm.load(fl[:-12] + 'hdf5'), 0)[12:-12, 12:-12]\n",
    "                    \n",
    "            lq, hq = np.nanpercentile(mean_img, [.5, 99.5])\n",
    "            pl.imshow(mean_img, vmin=lq, vmax=hq)\n",
    "            pl.title('Mean')\n",
    "        #        pl.plot(ld['correlations'])\n",
    "\n",
    "            pl.subplot(len(fls), 4, 4 * cnt + 2)\n",
    "            pl.imshow(ld['img_corr'], vmin=0, vmax=.35)\n",
    "            pl.title('Corr image')\n",
    "    #        pl.colorbar()\n",
    "            pl.subplot(len(fls), 4, 4 * cnt + 3)\n",
    "    #\n",
    "            pl.plot(ld['norms'])\n",
    "            pl.xlabel('frame')\n",
    "            pl.ylabel('norm opt flow')\n",
    "            pl.subplot(len(fls), 4, 4 * cnt + 4)\n",
    "            flows = ld['flows']\n",
    "            pl.imshow(np.mean(\n",
    "                np.sqrt(flows[:, :, :, 0]**2 + flows[:, :, :, 1]**2), 0), vmin=0, vmax=0.3)\n",
    "            pl.colorbar()\n",
    "            pl.title('Mean optical flow')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# MEMORY MAPPING: save each chunk in F format on memory mapped files\n",
    "t1 = time.time()\n",
    "if not params_movie.has_key('max_shifts'):\n",
    "    fnames = [params_movie['fname']]\n",
    "    border_to_0 = 0\n",
    "elif not params_movie.has_key('overlaps'):\n",
    "    fnames = [mc.fname_tot_rig]\n",
    "    border_to_0 = bord_px_rig\n",
    "    m_els = m_rig\n",
    "else:\n",
    "    fnames = [mc.fname_tot_els]\n",
    "    border_to_0 = bord_px_els\n",
    "    \n",
    "# if you need to crop the borders use slicing    \n",
    "# idx_x=slice(border_nan,-border_nan,None)\n",
    "# idx_y=slice(border_nan,-border_nan,None)\n",
    "# idx_xy=(idx_x,idx_y)\n",
    "idx_xy = None\n",
    "add_to_movie = -np.nanmin(m_els) + 1  # movie must be positive\n",
    "# if you need to remove frames from the beginning of each file\n",
    "remove_init = 0\n",
    "# downsample movie in time: use .2 or .1 if file is large and you want a quick answer             \n",
    "downsample_factor = 1 \n",
    "base_name = fname.split('/')[-1][:-4]\n",
    "name_new = cm.save_memmap_each(fnames, dview=dview, base_name=base_name, resize_fact=(\n",
    "    1, 1, downsample_factor), remove_init=remove_init, idx_xy=idx_xy, add_to_movie=add_to_movie, border_to_0=border_to_0)\n",
    "name_new.sort()\n",
    "print(name_new)\n",
    "\n",
    "#%% concatenate chunks if needed\n",
    "if len(name_new) > 1:\n",
    "    fname_new = cm.save_memmap_join(\n",
    "        name_new, base_name='Yr', n_chunks=12, dview=dview)\n",
    "else:\n",
    "    print('One file only, not saving!')\n",
    "    fname_new = name_new[0]\n",
    "\n",
    "t2 = time.time() - t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%% LOAD MEMMAP FILE\n",
    "# fname_new='Yr_d1_501_d2_398_d3_1_order_F_frames_369_.mmap'\n",
    "Yr, dims, T = cm.load_memmap(fname_new)\n",
    "d1, d2 = dims\n",
    "images = np.reshape(Yr.T, [T] + list(dims), order='F')\n",
    "Y = np.reshape(Yr, dims + (T,), order='F')\n",
    "m_images = cm.movie(images)\n",
    "#%%  checks on movies (might take time if large!)\n",
    "if np.min(images) < 0:\n",
    "    raise Exception('Movie too negative, add_to_movie should be larger')\n",
    "if np.sum(np.isnan(images)) > 0:\n",
    "    raise Exception('Movie contains nan! You did not remove enough borders')\n",
    "#%% correlation image\n",
    "Cn = cm.local_correlations(Y)\n",
    "Cn[np.isnan(Cn)] = 0\n",
    "pl.imshow(Cn, cmap='gray', vmax=.35)\n",
    "#%% some parameter settings\n",
    "# order of the autoregressive fit to calcium imaging in general one (slow gcamps) or two (fast gcamps fast scanning)\n",
    "p = params_movie['p']  \n",
    "# merging threshold, max correlation allowed\n",
    "merge_thresh= params_movie['merge_thresh'] \n",
    "# half-size of the patches in pixels. rf=25, patches are 50x50\n",
    "rf = params_movie['rf']  \n",
    "# amounpl.it of overlap between the patches in pixels\n",
    "stride_cnmf = params_movie['stride_cnmf'] \n",
    " # number of components per patch\n",
    "K =  params_movie['K'] \n",
    "# if dendritic. In this case you need to set init_method to sparse_nmf\n",
    "is_dendrites = params_movie['is_dendrites']\n",
    "# iinit method can be greedy_roi for round shapes or sparse_nmf for denritic data\n",
    "init_method = params_movie['init_method']\n",
    "# expected half size of neurons\n",
    "gSig = params_movie['gSig']  \n",
    "# this controls sparsity\n",
    "alpha_snmf = params_movie['alpha_snmf']  \n",
    "#frame rate of movie (even considering eventual downsampling)\n",
    "final_frate = params_movie['final_frate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if params_movie['is_dendrites'] == True:\n",
    "    if params_movie['init_method'] is not 'sparse_nmf':\n",
    "        raise Exception('dendritic requires sparse_nmf')\n",
    "    if params_movie['alpha_snmf'] is None:\n",
    "        raise Exception('need to set a value for alpha_snmf')\n",
    "#%% Extract spatial and temporal components on patches\n",
    "t1 = time.time()\n",
    "cnm = cnmf.CNMF(n_processes, k=K, gSig=gSig, merge_thresh=0.8, p=0, dview=dview, Ain=None, rf=rf, stride=stride_cnmf, memory_fact=1,\n",
    "                method_init=init_method, alpha_snmf=alpha_snmf, only_init_patch=True, gnb=1, method_deconvolution='oasis')\n",
    "cnm = cnm.fit(images)\n",
    "\n",
    "A_tot = cnm.A\n",
    "C_tot = cnm.C\n",
    "YrA_tot = cnm.YrA\n",
    "b_tot = cnm.b\n",
    "f_tot = cnm.f\n",
    "sn_tot = cnm.sn\n",
    "t2 = time.time() - t1\n",
    "print(('Number of components:' + str(A_tot.shape[-1])))\n",
    "#%%\n",
    "pl.figure()\n",
    "crd = plot_contours(A_tot, Cn, thr=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%% DISCARD LOW QUALITY COMPONENT\n",
    "t1 = time.time()\n",
    "final_frate = params_movie['final_frate']\n",
    "r_values_min = .7  # threshold on space consistency\n",
    "fitness_min = -40  # threshold on time variability\n",
    "# threshold on time variability (if nonsparse activity)\n",
    "fitness_delta_min = -40\n",
    "Npeaks = 10\n",
    "traces = C_tot + YrA_tot\n",
    "idx_components, idx_components_bad = cm.components_evaluation.estimate_components_quality(\n",
    "    traces, Y, A_tot, C_tot, b_tot, f_tot, final_frate=final_frate, Npeaks=Npeaks, r_values_min=r_values_min, fitness_min=fitness_min, fitness_delta_min=fitness_delta_min)\n",
    "t2 = time.time() - t1\n",
    "print(('Keeping ' + str(len(idx_components)) +\n",
    "       ' and discarding  ' + str(len(idx_components_bad))))\n",
    "#%%\n",
    "pl.figure()\n",
    "crd = plot_contours(A_tot.tocsc()[:, idx_components], Cn, thr=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%%\n",
    "A_tot = A_tot.tocsc()[:, idx_components]\n",
    "C_tot = C_tot[idx_components]\n",
    "#%% rerun updating the components to refine\n",
    "cnm = cnmf.CNMF(n_processes, k=A_tot.shape, gSig=gSig, merge_thresh=merge_thresh, p=p, dview=dview, Ain=A_tot, Cin=C_tot,\n",
    "                f_in=f_tot, rf=None, stride=None, method_deconvolution='oasis')\n",
    "cnm = cnm.fit(images)\n",
    "#%%\n",
    "A, C, b, f, YrA, sn = cnm.A, cnm.C, cnm.b, cnm.f, cnm.YrA, cnm.sn\n",
    "#%% again recheck quality of components, stricter criteria\n",
    "final_frate = params_movie['final_frate']\n",
    "r_values_min = .75\n",
    "fitness_min = - 50\n",
    "fitness_delta_min = - 50\n",
    "Npeaks = 10\n",
    "traces = C + YrA\n",
    "idx_components, idx_components_bad = cm.components_evaluation.estimate_components_quality(\n",
    "    traces, Y, A, C, b, f, final_frate=final_frate, Npeaks=Npeaks, r_values_min=r_values_min, fitness_min=fitness_min, fitness_delta_min=fitness_delta_min)\n",
    "print(' ***** ')\n",
    "print((len(traces)))\n",
    "print((len(idx_components)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%% visualize included and excluded components\n",
    "pl.subplot(1, 2, 1)\n",
    "crd = plot_contours(A.tocsc()[:, idx_components], Cn, thr=0.9)\n",
    "pl.subplot(1, 2, 2)\n",
    "crd = plot_contours(A.tocsc()[:, idx_components_bad], Cn, thr=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%% visualize spatial and temporal components\n",
    "view_patches_bar(Yr, scipy.sparse.coo_matrix(A.tocsc()[:, idx_components]), C[\n",
    "    idx_components, :], b, f, dims[0], dims[1], YrA=YrA[idx_components, :], img=Cn)\n",
    "#%%\n",
    "view_patches_bar(Yr, scipy.sparse.coo_matrix(A.tocsc()[:, idx_components_bad]), C[\n",
    "    idx_components_bad, :], b, f, dims[0], dims[1], YrA=YrA[idx_components_bad, :], img=Cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%% save results\n",
    "np.savez(os.path.join(os.path.split(fname_new)[0], os.path.split(fname_new)[1][:-4] + 'results_analysis.npz'), Cn=Cn, A=A.todense(\n",
    "), C=C, b=b, f=f, YrA=YrA, sn=sn, d1=d1, d2=d2, idx_components=idx_components, idx_components_bad=idx_components_bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%% STOP CLUSTER and clean up log files\n",
    "cm.stop_server()\n",
    "log_files = glob.glob('Yr*_LOG_*')\n",
    "for log_file in log_files:\n",
    "    os.remove(log_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    \n",
    "#%% reconstruct denoised movie\n",
    "denoised = cm.movie(A.dot(C) + b.dot(f)).reshape(dims+(-1,),order = 'F').transpose([2,0,1])\n",
    "#%% \n",
    "denoised.play(gain = 10, offset = 0,fr =100, magnification = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%% reconstruct denoised movie without background\n",
    "denoised = cm.movie(A.dot(C)).reshape(dims+(-1,),order = 'F').transpose([2,0,1])\n",
    "#%%\n",
    "denoised.play(gain = 30, offset = 0,fr =100, magnification = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
