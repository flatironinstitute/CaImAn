{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Volumetric data processing\n",
    "This is a simple demo on toy 3d data for source extraction and deconvolution using CaImAn.\n",
    "For more information check demo_pipeline.ipynb which performs the complete pipeline for\n",
    "2d two photon imaging data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "try:\n",
    "    get_ipython().magic(u'load_ext autoreload')\n",
    "    get_ipython().magic(u'autoreload 2')\n",
    "    print(1)\n",
    "except:\n",
    "    print('NOT IPYTHON')\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import psutil\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "from ipyparallel import Client\n",
    "\n",
    "import caiman as cm\n",
    "from caiman.utils.visualization import nb_view_patches3d\n",
    "import caiman.source_extraction.cnmf as cnmf\n",
    "from caiman.components_evaluation import evaluate_components, estimate_components_quality_auto\n",
    "from caiman.cluster import setup_cluster\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import bokeh.plotting as bpl\n",
    "bpl.output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop the cluster if one exists\n",
    "n_processes = psutil.cpu_count()\n",
    "print('using ' + str(n_processes) + ' processes')\n",
    "print(\"Stopping  cluster to avoid unnencessary use of memory....\")\n",
    "sys.stdout.flush()  \n",
    "cm.stop_server()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to create some toy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_data(p=1, noise=1., T=256, framerate=30, firerate=2., plot=False):\n",
    "    if p == 2:\n",
    "        gamma = np.array([1.5, -.55])\n",
    "    elif p == 1:\n",
    "        gamma = np.array([.9])\n",
    "    else:\n",
    "        raise\n",
    "    dims = (30, 40, 50)  # size of image\n",
    "    sig = (2, 2, 2)  # neurons size\n",
    "    bkgrd = 10\n",
    "    N = 20  # number of neurons\n",
    "    np.random.seed(7)\n",
    "    centers = np.asarray([[np.random.randint(5, x - 5)\n",
    "                           for x in dims] for i in range(N)])\n",
    "    Yr = np.zeros(dims + (T,), dtype=np.float32)\n",
    "    trueSpikes = np.random.rand(N, T) < firerate / float(framerate)\n",
    "    trueSpikes[:, 0] = 0\n",
    "    truth = trueSpikes.astype(np.float32)\n",
    "    for i in range(2, T):\n",
    "        if p == 2:\n",
    "            truth[:, i] += gamma[0] * truth[:, i - 1] + gamma[1] * truth[:, i - 2]\n",
    "        else:\n",
    "            truth[:, i] += gamma[0] * truth[:, i - 1]\n",
    "    for i in range(N):\n",
    "        Yr[centers[i, 0], centers[i, 1], centers[i, 2]] = truth[i]\n",
    "    tmp = np.zeros(dims)\n",
    "    tmp[15, 20, 25] = 1.\n",
    "    z = np.linalg.norm(gaussian_filter(tmp, sig).ravel())\n",
    "    Yr = bkgrd + noise * np.random.randn(*(dims + (T,))) + 10 * gaussian_filter(Yr, sig + (0,)) / z\n",
    "    d1, d2, d3, T = Yr.shape\n",
    "    Yr = np.reshape(Yr, (d1 * d2 * d3, T), order='F').astype(np.float32)\n",
    "\n",
    "    if plot:\n",
    "        Y = np.reshape(Yr, (d1, d2, d3, T), order='F')\n",
    "        plt.figure(figsize=(15, 3))\n",
    "        plt.plot(truth.T)\n",
    "        plt.figure(figsize=(15, 3))\n",
    "        for c in centers:\n",
    "            plt.plot(Y[c[0], c[1], c[2]])\n",
    "\n",
    "        plt.figure(figsize=(15, 4))\n",
    "        plt.subplot(131)\n",
    "        plt.scatter(*centers.T[::-1], c='g')\n",
    "        plt.imshow(Y.max(0).max(-1), cmap='hot')\n",
    "        plt.title('Max.proj. x & t')\n",
    "        plt.subplot(132)\n",
    "        plt.scatter(*centers.T[[2, 0, 1]], c='g')\n",
    "        plt.imshow(Y.max(1).max(-1), cmap='hot')\n",
    "        plt.title('Max.proj. y & t')\n",
    "        plt.subplot(133)\n",
    "        plt.scatter(*centers.T[[1, 0, 2]], c='g')\n",
    "        plt.imshow(Y.max(2).max(-1), cmap='hot')\n",
    "        plt.title('Max.proj. z & t')\n",
    "        plt.show()\n",
    "\n",
    "    return Yr, truth, trueSpikes, centers, dims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data creation and memory mapping\n",
    "- create a toy 3d dataset if it doesn't exist.\n",
    "- perform memory mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "#%% SAVING TIFF FILE ON A SINGLE MEMORY MAPPABLE FILE\n",
    "try:\n",
    "    fname_new = cm.save_memmap(['../../example_movies/demoMovie3D.tif'], base_name='Yr', is_3D=True, order='C')\n",
    "except:  # %% create 3d tiff file if not yet existent\n",
    "    from skimage.external.tifffile import imsave\n",
    "    Yr, truth, trueSpikes, centers, dims = gen_data(p=2)\n",
    "    data = np.transpose(Yr.reshape(dims + (-1,), order='F'), [3, 0, 1, 2])\n",
    "    imsave('../../example_movies/demoMovie3D.tif', data)\n",
    "    fname_new = cm.save_memmap(['../../example_movies/demoMovie3D.tif'], base_name='Yr', is_3D=True)\n",
    "\n",
    "print(fname_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load memory mapped file and show a max-projection of the correlation image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yr, dims, T = cm.load_memmap(fname_new)\n",
    "Y = np.reshape(Yr, dims + (T,), order='F')\n",
    "Cn = cm.local_correlations(Y)\n",
    "plt.imshow(Cn.max(0) if len(Cn.shape) == 3 else Cn, cmap='gray',\n",
    "           vmin=np.percentile(Cn, 1), vmax=np.percentile(Cn, 99))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run CNMF\n",
    "### If data is small enough use a single patch approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters\n",
    "K = 20  # number of neurons expected per patch\n",
    "gSig = [2, 2, 2]  # expected half size of neurons\n",
    "merge_thresh = 0.8  # merging threshold, max correlation allowed\n",
    "p = 2  # order of the autoregressive system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# START CLUSTER\n",
    "c, dview, n_processes = setup_cluster(\n",
    "    backend='local', n_processes=None, single_thread=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize CNMF object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INIT\n",
    "cnm = cnmf.CNMF(n_processes, method_init='greedy_roi', k=K, gSig=gSig, merge_thresh=merge_thresh,\n",
    "                p=p, dview=dview, Ain=None, method_deconvolution='oasis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run CNMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# FIT\n",
    "images = np.reshape(Yr.T, [T] + list(dims), order='F')    # reshape data in Python format (T x X x Y x Z)\n",
    "cnm = cnm.fit(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View components per layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view components per layer\n",
    "traces_fluo = nb_view_patches3d(cnm.YrA, cnm.A, cnm.C,dims, thr=0.9, \n",
    "                                image_type='max', max_projection=False,\n",
    "                                denoised_color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run CNMF\n",
    "### For larger data use a patch approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "rf = (15, 15, 15)  # half-size of the patches in pixels. rf=25, patches are 50x50\n",
    "stride = (10, 10, 10)  # amounpl.it of overlap between the patches in pixels\n",
    "K = 12  # number of neurons expected per patch\n",
    "gSig = [2, 2, 2]  # expected half size of neurons\n",
    "merge_thresh = 0.8  # merging threshold, max correlation allowed\n",
    "p = 2  # order of the autoregressive system\n",
    "save_results = False\n",
    "#%% RUN ALGORITHM ON PATCHES\n",
    "init_method = 'greedy_roi'\n",
    "alpha_snmf = None  # 10e2  # this controls sparsity\n",
    "\n",
    "cnm = cnmf.CNMF(n_processes, k=K, gSig=gSig, merge_thresh=0.8, p=p, dview=dview, Ain=None, rf=rf, stride=stride, memory_fact=1,\n",
    "                method_init=init_method, alpha_snmf=alpha_snmf, only_init_patch=True, gnb=1, method_deconvolution='oasis')\n",
    "cnm = cnm.fit(images)\n",
    "\n",
    "A_tot = cnm.A\n",
    "C_tot = cnm.C\n",
    "YrA_tot = cnm.YrA\n",
    "b_tot = cnm.b\n",
    "f_tot = cnm.f\n",
    "sn_tot = cnm.sn\n",
    "\n",
    "print(('Number of components:' + str(A_tot.shape[-1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Component Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% COMPONENT EVALUATION\n",
    "# the components are evaluated in two ways:\n",
    "#   a) the shape of each component must be correlated with the data\n",
    "#   b) a minimum peak SNR is required over the length of a transient\n",
    "\n",
    "fr = 10 # approx final rate  (after eventual downsampling )\n",
    "decay_time = 1.  # length of typical transient in seconds \n",
    "use_cnn = False  # CNN classifier is designed for 2d (real) data\n",
    "min_SNR = 3      # accept components with that peak-SNR or higher\n",
    "rval_thr = 0.7   # accept components iwth speace correlation threshold or higher\n",
    "\n",
    "idx_components, idx_components_bad, SNR_comp, r_values, cnn_preds = \\\n",
    "    estimate_components_quality_auto(images, cnm.A, cnm.C, cnm.b, cnm.f, \n",
    "                                     cnm.YrA, fr, decay_time, gSig, dims, \n",
    "                                     dview = dview, min_SNR=min_SNR, \n",
    "                                     r_values_min = rval_thr, use_cnn = use_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# evaluate_components\n",
    "final_frate = 10  # approx final rate  (after eventual downsampling )\n",
    "Npeaks = 10\n",
    "traces = C_tot + YrA_tot\n",
    "#        traces_a=traces-scipy.ndimage.percentile_filter(traces,8,size=[1,np.shape(traces)[-1]/5])\n",
    "#        traces_b=np.diff(traces,axis=1)\n",
    "fitness_raw, fitness_delta, erfc_raw, erfc_delta, r_values, significant_samples = evaluate_components(\n",
    "    Y, traces, A_tot, C_tot, b_tot, f_tot, final_frate, remove_baseline=False, N=5, robust_std=False, Athresh=0.1, Npeaks=Npeaks,  thresh_C=0.3)\n",
    "\n",
    "idx_components_r = np.where(r_values >= .7)[0]\n",
    "idx_components_raw = np.where(fitness_raw < -60)[0]\n",
    "idx_components_delta = np.where(fitness_delta < -20)[0]\n",
    "\n",
    "idx_components = np.union1d(idx_components_r, idx_components_raw)\n",
    "idx_components = np.union1d(idx_components, idx_components_delta)\n",
    "idx_components_bad = np.setdiff1d(list(range(len(traces))), idx_components)\n",
    "\n",
    "print(('Keeping ' + str(len(idx_components)) +\n",
    "       ' and discarding  ' + str(len(idx_components_bad))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "select only the good components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_tot = cnm.A[:, idx_components]\n",
    "C_tot = cnm.C[idx_components]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-run seeded CNMF\n",
    "Now we re-run CNMF on the whole FOV seeded with `A_tot`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# fit good components again\n",
    "cnm = cnmf.CNMF(n_processes, k=A_tot.shape, gSig=gSig, merge_thresh=merge_thresh, p=p, dview=dview,\n",
    "                Ain=A_tot, Cin=C_tot, f_in=f_tot, rf=None, stride=None, method_deconvolution='oasis')\n",
    "cnm = cnm.fit(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view components as max-projection along x, y and z\n",
    "traces_fluo = nb_view_patches3d(cnm.YrA, cnm.A, cnm.C, dims, Yr=Yr,\n",
    "                                image_type='corr', max_projection=True,\n",
    "                                denoised_color='green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STOP CLUSTER\n",
    "dview.terminate()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
