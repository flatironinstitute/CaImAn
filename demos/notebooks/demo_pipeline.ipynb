{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html><head><meta content=\"text/html; charset=UTF-8\" http-equiv=\"content-type\"><style type=\"text/css\">ol</style></head><body class=\"c5\"><p class=\"c0 c4\"><span class=\"c3\"></span></p><p class=\"c2 title\" id=\"h.rrbabt268i6e\"><h1>CaImAn&rsquo;s Demo pipeline</h1></p><p class=\"c0\"><span class=\"c3\">This notebook will help to demonstrate the process of CaImAn and how it uses different functions to denoise, deconvolve and demix neurons from a Calcium Imaging Video. </span></p>\n",
    "<p><img src=\"../../docs/img/quickintro.png\" /></p>\n",
    "<p class=\"c0\"><span class=\"c3\">More information can be found in CaImAn&rsquo;s documentation. </span></p>\n",
    "</html>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from builtins import zip\n",
    "from builtins import str\n",
    "from builtins import map\n",
    "from builtins import range\n",
    "from past.utils import old_div\n",
    "\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "try:\n",
    "    cv2.setNumThreads(0)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    if __IPYTHON__:\n",
    "        print((1))\n",
    "        # this is used for debugging purposes only. allows to reload classes\n",
    "        # when changed\n",
    "        get_ipython().magic('load_ext autoreload')\n",
    "        get_ipython().magic('autoreload 2')\n",
    "except NameError:\n",
    "    print('Not IPYTHON')\n",
    "    pass\n",
    "\n",
    "import caiman as cm\n",
    "from caiman.utils.utils import download_demo\n",
    "from caiman.utils.visualization import plot_contours, nb_view_patches, nb_plot_contour\n",
    "from caiman.source_extraction.cnmf import cnmf as cnmf\n",
    "from caiman.motion_correction import MotionCorrect\n",
    "from caiman.source_extraction.cnmf.utilities import detrend_df_f\n",
    "from caiman.components_evaluation import estimate_components_quality_auto\n",
    "import bokeh.plotting as bpl\n",
    "bpl.output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup some parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dataset dependent parameters\n",
    "fname = ['Sue_2x_3000_40_-46.tif']  # filename to be processed\n",
    "fr = 30                             # imaging rate in frames per second\n",
    "decay_time = 0.4                    # length of a typical transient in seconds\n",
    "\n",
    "# motion correction parameters\n",
    "niter_rig = 1               # number of iterations for rigid motion correction\n",
    "max_shifts = (6, 6)         # maximum allow rigid shift\n",
    "splits_rig = 56             # for parallelization split the movies in  num_splits chuncks across time\n",
    "strides = (48, 48)          # start a new patch for pw-rigid motion correction every x pixels\n",
    "overlaps = (24, 24)         # overlap between pathes (size of patch strides+overlaps)\n",
    "splits_els = 56             # for parallelization split the movies in  num_splits chuncks across time\n",
    "upsample_factor_grid = 4    # upsample factor to avoid smearing when merging patches\n",
    "max_deviation_rigid = 3     # maximum deviation allowed for patch with respect to rigid shifts\n",
    "\n",
    "# parameters for source extraction and deconvolution\n",
    "p = 1                       # order of the autoregressive system\n",
    "gnb = 2                     # number of global background components\n",
    "merge_thresh = 0.8          # merging threshold, max correlation allowed\n",
    "rf = 15                     # half-size of the patches in pixels. e.g., if rf=25, patches are 50x50\n",
    "stride_cnmf = 6             # amount of overlap between the patches in pixels\n",
    "K = 4                       # number of components per patch\n",
    "gSig = [4, 4]               # expected half size of neurons\n",
    "init_method = 'greedy_roi'  # initialization method (if analyzing dendritic data using 'sparse_nmf')\n",
    "is_dendrites = False        # flag for analyzing dendritic data\n",
    "alpha_snmf = None           # sparsity penalty for dendritic data analysis through sparse NMF\n",
    "\n",
    "# parameters for component evaluation\n",
    "min_SNR = 2.5               # signal to noise ratio for accepting a component\n",
    "rval_thr = 0.8              # space correlation threshold for accepting a component\n",
    "cnn_thr = 0.8               # threshold for CNN based classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the dataset if not already present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if fname[0] in ['Sue_2x_3000_40_-46.tif','demoMovieJ.tif']:\n",
    "    fname = [download_demo(fname[0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play the movie (optional). This will require loading the movie in memory which in general is not needed by the pipeline. Displaying the movie uses the OpenCV library. Press `q` to close the video panel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m_orig = cm.load_movie_chain(fname[:1])\n",
    "downsample_ratio = 0.2\n",
    "offset_mov = -np.min(m_orig[:100])  # make the dataset mostly non-negative\n",
    "m_orig.resize(1, 1, downsample_ratio).play(\n",
    "gain=10, offset=offset_mov, fr=30, magnification=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Setup a cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%% start a cluster for parallel processing\n",
    "c, dview, n_processes = cm.cluster.setup_cluster(\n",
    "    backend='local', n_processes=None, single_thread=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motion Correction\n",
    "First we create a motion correction object with the parameters specified. Note that the file is not loaded in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# first we create a motion correction object with the parameters specified\n",
    "min_mov = min(cm.load(fname[0], subindices=range(200)).min(),0) \n",
    "        # this will be subtracted from the movie to make it non-negative \n",
    "\n",
    "mc = MotionCorrect(fname[0], min_mov,\n",
    "                   dview=dview, max_shifts=max_shifts, niter_rig=niter_rig,\n",
    "                   splits_rig=splits_rig, \n",
    "                   strides= strides, overlaps= overlaps, splits_els=splits_els,\n",
    "                   upsample_factor_grid=upsample_factor_grid,\n",
    "                   max_deviation_rigid=max_deviation_rigid, \n",
    "                   shifts_opencv = True, nonneg_movie = True)\n",
    "# note that the file is not loaded in memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now perform motion correction. From the movie above we see that the dateset exhibits non-uniform motion. We will perform piecewise rigid motion correction using the NoRMCorre algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "#%% Run piecewise-rigid motion correction using NoRMCorre\n",
    "mc.motion_correct_pwrigid(save_movie=True)\n",
    "m_els = cm.load(mc.fname_tot_els)\n",
    "bord_px_els = np.ceil(np.maximum(np.max(np.abs(mc.x_shifts_els)),\n",
    "                                 np.max(np.abs(mc.y_shifts_els)))).astype(np.int)  \n",
    "    # maximum shift to be used for trimming against NaNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the results by comparing the original movie. A more detailed presentation of the motion correction method can be found in the [demo motion correction](./demo_motion_correction.ipynb) notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%% compare with original movie\n",
    "cm.concatenate([m_orig.resize(1, 1, downsample_ratio)+offset_mov,\n",
    "                m_els.resize(1, 1, downsample_ratio)], \n",
    "               axis=2).play(fr=60, gain=15, magnification=2, offset=0)  # press q to exit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory mapping \n",
    "\n",
    "The cell below memory maps the file in order `C` and then loads the new memory mapped file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%% MEMORY MAPPING\n",
    "# memory map the file in order 'C'\n",
    "fnames = mc.fname_tot_els   # name of the pw-rigidly corrected file.\n",
    "border_to_0 = bord_px_els     # number of pixels to exclude\n",
    "fname_new = cm.save_memmap(fnames, base_name='memmap_', order = 'C',\n",
    "                           border_to_0 = bord_px_els) # exclude borders\n",
    "\n",
    "# now load the file\n",
    "Yr, dims, T = cm.load_memmap(fname_new)\n",
    "d1, d2 = dims\n",
    "images = np.reshape(Yr.T, [T] + list(dims), order='F') \n",
    "    #load frames in python format (T x X x Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now restart the cluster to clean up the memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%% restart cluster to clean up memory\n",
    "dview.terminate()\n",
    "c, dview, n_processes = cm.cluster.setup_cluster(\n",
    "    backend='local', n_processes=None, single_thread=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run CNMF on patches in parallel\n",
    "\n",
    "<p> <img src=\"../../docs/img/cnmf1.png\" /> </p>\n",
    "\n",
    "- The FOV is split is different overlapping patches that are subsequently processed in parallel by the CNMF algorithm.\n",
    "- The results from all the patches are merged with special attention to idendtified components on the border.\n",
    "- The results are then refined by additional CNMF iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "#%% RUN CNMF ON PATCHES\n",
    "\n",
    "# First extract spatial and temporal components on patches and combine them\n",
    "# for this step deconvolution is turned off (p=0)\n",
    "t1 = time.time()\n",
    "\n",
    "cnm = cnmf.CNMF(n_processes=1, k=K, gSig=gSig, merge_thresh= merge_thresh, \n",
    "                p = 0,  dview=dview, rf=rf, stride=stride_cnmf, memory_fact=1,\n",
    "                method_init=init_method, alpha_snmf=alpha_snmf, \n",
    "                only_init_patch = False, gnb = gnb, border_pix = bord_px_els) \n",
    "cnm = cnm.fit(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot contours of identified components against correlation image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%% plot contours of found components\n",
    "Cn = cm.local_correlations(images.transpose(1,2,0))\n",
    "Cn[np.isnan(Cn)] = 0\n",
    "plt.figure(); crd = plot_contours(cnm.A, Cn, thr=0.9)\n",
    "plt.title('Contour plots of found components')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Component Evaluation\n",
    "\n",
    "The processing in patches creates several spurious components. These are filtered out by evaluating each component using three different criteria:\n",
    "\n",
    "- the shape of each component must be correlated with the data at the corresponding location within the FOV\n",
    "- a minimum peak SNR is required over the length of a transient\n",
    "- each shape passes a CNN based classifier\n",
    "\n",
    "<img src=\"../../docs/img/evaluationcomponent.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%% COMPONENT EVALUATION\n",
    "# the components are evaluated in three ways:\n",
    "#   a) the shape of each component must be correlated with the data\n",
    "#   b) a minimum peak SNR is required over the length of a transient\n",
    "#   c) each shape passes a CNN based classifier\n",
    "\n",
    "idx_components, idx_components_bad, SNR_comp, r_values, cnn_preds = \\\n",
    "    estimate_components_quality_auto(images, cnm.A, cnm.C, cnm.b, cnm.f, \n",
    "                                     cnm.YrA, fr, decay_time, gSig, dims, \n",
    "                                     dview = dview, min_SNR=min_SNR, \n",
    "                                     r_values_min = rval_thr, use_cnn = False, \n",
    "                                     thresh_cnn_lowest = cnn_thr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot contours of selected and rejected components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%% PLOT COMPONENTS\n",
    "\n",
    "plt.figure();\n",
    "plt.subplot(121); crd_good = cm.utils.visualization.plot_contours(cnm.A[:,idx_components], Cn, thr=.8, vmax=0.75)\n",
    "plt.title('Contour plots of accepted components')\n",
    "plt.subplot(122); crd_bad = cm.utils.visualization.plot_contours(cnm.A[:,idx_components_bad], Cn, thr=.8, vmax=0.75)\n",
    "plt.title('Contour plots of rejected components')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View traces of accepted and rejected components. Note that if you get data rate error you can start Jupyter notebooks using:\n",
    "'jupyter notebook --NotebookApp.iopub_data_rate_limit=1.0e10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# accepted components\n",
    "nb_view_patches(Yr, cnm.A.tocsc()[:, idx_components], cnm.C[idx_components], \n",
    "                cnm.b, cnm.f, dims[0], dims[1], YrA=cnm.YrA[idx_components], image_neurons =Cn,\n",
    "                denoised_color = 'red');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rejected components\n",
    "if len(idx_components_bad) > 0:\n",
    "    nb_view_patches(Yr, cnm.A.tocsc()[:, idx_components_bad], cnm.C[idx_components_bad], \n",
    "                    cnm.b, cnm.f, dims[0], dims[1], YrA=cnm.YrA[idx_components_bad], image_neurons =Cn,\n",
    "                    denoised_color = 'red');\n",
    "else:\n",
    "    print(\"No components were rejected.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-run (seeded) CNMF  on the full Field of View  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "#%% RE-RUN seeded CNMF on accepted patches to refine and perform deconvolution \n",
    "A_in, C_in, b_in, f_in = cnm.A[:,idx_components], cnm.C[idx_components], cnm.b, cnm.f\n",
    "cnm2 = cnmf.CNMF(n_processes=1, k=A_in.shape[-1], gSig=gSig, p=p, dview=dview,\n",
    "                merge_thresh=merge_thresh,  Ain=A_in, Cin=C_in, b_in = b_in,\n",
    "                f_in=f_in, rf = None, stride = None, gnb = gnb, \n",
    "                method_deconvolution='oasis', check_nan = True)\n",
    "\n",
    "cnm2 = cnm2.fit(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract DF/F values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%% Extract DF/F values\n",
    "\n",
    "F_dff = detrend_df_f(cnm2.A, cnm2.b, cnm2.C, cnm2.f, YrA = cnm2.YrA, \n",
    "                      quantileMin=8, frames_window=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "discard_traces_fluo=nb_view_patches(Yr,cnm2.A, cnm2.C, cnm2.b, cnm2.f,\n",
    "                                    dims[0], dims[1], thr = 0.8, image_neurons=Cn,\n",
    "                                    denoised_color='red')\n",
    "print('you will may be need to change the data rate to generate this one: use jupyter notebook --NotebookApp.iopub_data_rate_limit=1.0e10')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> closing, saving, and creating denoised version </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_results = False\n",
    "if save_results:\n",
    "    np.savez(os.path.join(os.path.split(fname_new)[0], \n",
    "                          os.path.split(fname_new)[1][:-4] + 'results_analysis.npz'),\n",
    "             Cn=Cn, A=cnm2.A.todense(), C=cnm2.C,\n",
    "             b=cnm2.b, f=cnm2.f, YrA=cnm2.YrA, sn=sn, d1=d1, d2=d2,\n",
    "             idx_components=idx_components, idx_components_bad=idx_components_bad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stop cluster and clean up LOG files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%% STOP CLUSTER and clean up log files\n",
    "cm.stop_server(dview=dview)\n",
    "log_files = glob.glob('*_LOG_*')\n",
    "for log_file in log_files:\n",
    "    os.remove(log_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can inspect the denoised results by reconstructing the movie and playing alongside the original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%% reconstruct denoised movie\n",
    "denoised = cm.movie(cnm2.A.dot(cnm2.C) + \\\n",
    "                    cnm2.b.dot(cnm2.f)).reshape(dims + (-1,), order='F').transpose([2, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%% play along side original data\n",
    "cm.concatenate([m_els.resize(1, 1, downsample_ratio),\n",
    "                denoised.resize(1, 1, downsample_ratio)], \n",
    "                axis=2).play(fr=60, gain=15, magnification=2, offset=0)  # press q to exit"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
