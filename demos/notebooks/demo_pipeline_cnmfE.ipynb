{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html><head><meta content=\"text/html; charset=UTF-8\" http-equiv=\"content-type\"><style type=\"text/css\">ol</style></head><body class=\"c5\"><p class=\"c0 c4\"><span class=\"c3\"></span></p><p class=\"c2 title\" id=\"h.rrbabt268i6e\"><h1>CaImAn&rsquo;s Demo pipeline</h1></p><p class=\"c0\"><span class=\"c3\">This notebook will help to demonstrate the process of CaImAn and how it uses different functions to denoise, deconvolve and demix neurons from a Calcium Imaging Video. </span></p>\n",
    "<p><img src=\"../../docs/img/quickintro.png\" /></p>\n",
    "<p class=\"c0\"><span class=\"c3\">More information can be found in CaImAn&rsquo;s documentation. </span></p>\n",
    "</html>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from builtins import zip\n",
    "from builtins import str\n",
    "from builtins import map\n",
    "from builtins import range\n",
    "from past.utils import old_div\n",
    "\n",
    "import os\n",
    "import sys\n",
    "caiman_path = os.path.join(\"..\", \"..\")\n",
    "sys.path.append(caiman_path)\n",
    "\n",
    "try:\n",
    "    get_ipython().magic(u'load_ext autoreload')\n",
    "    get_ipython().magic(u'autoreload 2')    \n",
    "except:\n",
    "    print('Not IPYTHON')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "get_ipython().magic(u'matplotlib qt')   \n",
    "import caiman as cm\n",
    "from caiman.source_extraction import cnmf\n",
    "from caiman.utils.utils import download_demo\n",
    "from caiman.utils.visualization import inspect_correlation_pnr\n",
    "from caiman.components_evaluation import estimate_components_quality_auto\n",
    "from caiman.motion_correction import motion_correct_oneP_rigid\n",
    "import os\n",
    "import cv2\n",
    "from caiman.utils.visualization import plot_contours, nb_view_patches, nb_plot_contour\n",
    "\n",
    "try:\n",
    "    cv2.setNumThreads(1)\n",
    "except:\n",
    "    print('Open CV is naturally single threaded')\n",
    "import bokeh.plotting as bpl\n",
    "bpl.output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup some parameters\n",
    "many of them will be set directly calling the CNMF object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fnames = ['data_endoscope.tif']\n",
    "frate = 10 # movie frame rate\n",
    "gSig = 3   # gaussian width of a 2D gaussian kernel, which approximates a neuron\n",
    "gSiz = 10  # average diameter of a neuron\n",
    "do_motion_correction = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the dataset if not already present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fnames = [download_demo(fnames[0], caiman_base=caiman_path)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Re)start cluster.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    dview.terminate() # stop it if it was running\n",
    "except:\n",
    "    pass\n",
    "\n",
    "c, dview, n_processes = cm.cluster.setup_cluster(backend='local', # use this one\n",
    "                                                 n_processes=24,  # number of process to use, if you go out of memory try to reduce this one\n",
    "                                                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of a memory mappable file. \n",
    "    - Performs motion correction and simultaneously creates a memory mappable file in F order\n",
    "    - Transforms into C order (much more efficient for parallel processing\n",
    "    - If you have multiple files there are ways to process many at the same time (not shown)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_motion_correction:\n",
    "    mc = motion_correct_oneP_rigid(fnames,                        # name of file to motion correct\n",
    "                               gSig_filt = [gSig]*2,                 # size of filter, xhange this one if algorithm does not work \n",
    "                               max_shifts = [5,5],                   # maximum shifts allowed in each direction \n",
    "                               dview=dview, \n",
    "                               splits_rig = 10,                      # number of chunks for parallelizing motion correction (remember that it should hold that length_movie/num_splits_to_process_rig>100) \n",
    "                               save_movie = True)                    # whether to save movie in memory mapped format\n",
    "    \n",
    "    new_templ = mc.total_template_rig\n",
    "    plt.figure(figsize=(15,8))\n",
    "    plt.subplot(1,2,1)    \n",
    "    plt.title('Filtered template')\n",
    "    plt.imshow(new_templ)       #% plot template\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.title('Estimated shifts')\n",
    "    plt.plot(mc.shifts_rig)     #% plot rigid shifts\n",
    "    plt.legend(['x shifts', 'y shifts'])\n",
    "    plt.xlabel('frames')\n",
    "    plt.ylabel('pixels')\n",
    "    \n",
    "    bord_px_rig = np.ceil(np.max(mc.shifts_rig)).astype(np.int)     #borders to eliminate from movie because of motion correction        \n",
    "    fname_new = cm.save_memmap([mc.fname_tot_rig], base_name='memmap_', order = 'C') # transforming memoruy mapped file in C order (efficient to perform computing)\n",
    "else:\n",
    "    #% create memory mappable file\n",
    "    fname_new = cm.save_memmap(fnames, base_name='memmap_', order = 'C')\n",
    "\n",
    "# load memory mappable file\n",
    "Yr, dims, T = cm.load_memmap(fname_new)\n",
    "Y = Yr.T.reshape((T,) + dims, order='F')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play the movie (optional). This will require loading the movie in memory which in general is not needed by the pipeline. Displaying the movie uses the OpenCV library. Press `q` to close the video panel. **BEWARE** the movie may appear in the background!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_orig = cm.movie(Y)\n",
    "downsample_ratio = 1.\n",
    "offset_mov = -np.min(m_orig[:100])  # make the dataset mostly non-negative\n",
    "m_orig.resize(1, 1, downsample_ratio).play(\n",
    "gain=2, offset=offset_mov, fr=30, magnification=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect summary images and set parameters\n",
    "Check the optimal values of min_corr and min_pnr by moving slider in the figure that pops up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute some summary images (correlation and peak to noise)\n",
    "cn_filter, pnr = cm.summary_images.correlation_pnr(Y, gSig=gSig, swap_dim=False) # change swap dim if output looks weird, it is a problem with tiffile\n",
    "# inspect the summary images and set the parameters\n",
    "inspect_correlation_pnr(cn_filter,pnr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "min_corr = .8 # min correlation of peak (from correlation image)\n",
    "min_pnr = 10 # min peak to noise ratio\n",
    "min_SNR = 3 # adaptive way to set threshold on the transient size\n",
    "r_values_min = 0.85  # threshold on space consistency (if you lower more components will be accepted, potentially with worst quality)\n",
    "decay_time = 0.4  #decay time of transients/indocator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set CNMF parameters and run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnm = cnmf.CNMF(n_processes=n_processes, \n",
    "                method_init='corr_pnr',                 # use this for 1 photon\n",
    "                k=70,                                   # neurons per patch\n",
    "                gSig=(3, 3),                            # half size of neuron\n",
    "                gSiz=(10, 10),                          # in general 3*gSig+1\n",
    "                merge_thresh=.8,                        # threshold for merging\n",
    "                p=1,                                    # order of autoregressive process to fit\n",
    "                dview=dview,                            # if None it will run on a single thread\n",
    "                tsub=2,                                 # downsampling factor in time for initialization, increase if you have memory problems             \n",
    "                ssub=2,                                 # downsampling factor in space for initialization, increase if you have memory problems\n",
    "                Ain=None,                               # if you want to initialize with some preselcted components you can pass them here as boolean vectors\n",
    "                rf=(40, 40),                            # half size of the patch (final patch will be 100x100)\n",
    "                stride=(20, 20),                        # overlap among patches (keep it at least large as 4 times the neuron size)\n",
    "                only_init_patch=True,                   # just leave it as is\n",
    "                gnb=16,                                 # number of background components\n",
    "                nb_patch=16,                            # number of background components per patch\n",
    "                method_deconvolution='oasis',           #could use 'cvxpy' alternatively\n",
    "                low_rank_background=True,               #leave as is\n",
    "                update_background_components=True,      # sometimes setting to False improve the results\n",
    "                min_corr=min_corr,                      # min peak value from correlation image \n",
    "                min_pnr=min_pnr,                        # min peak to noise ration from PNR image\n",
    "                normalize_init=False,                   # just leave as is\n",
    "                center_psf=True,                        # leave as is for 1 photon\n",
    "                del_duplicates=True)                    # whether to remove duplicates from initialization\n",
    "\n",
    "cnm.fit(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot contours of identified components against correlation image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crd = cm.utils.visualization.plot_contours(cnm.A, cn_filter, thr=.8, vmax=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Component Evaluation\n",
    "\n",
    "The processing in patches creates several spurious components. These are filtered out by evaluating each component using three different criteria:\n",
    "\n",
    "- the shape of each component must be correlated with the data at the corresponding location within the FOV\n",
    "- a minimum peak SNR is required over the length of a transient\n",
    "- each shape passes a CNN based classifier\n",
    "\n",
    "<img src=\"../../docs/img/evaluationcomponent.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% COMPONENT EVALUATION\n",
    "# the components are evaluated in three ways:\n",
    "#   a) the shape of each component must be correlated with the data\n",
    "#   b) a minimum peak SNR is required over the length of a transient\n",
    "#   c) each shape passes a CNN based classifier\n",
    "\n",
    "idx_components, idx_components_bad, comp_SNR, r_values, pred_CNN = estimate_components_quality_auto(\n",
    "                            Y, cnm.A, cnm.C, cnm.b, cnm.f, cnm.YrA, frate, \n",
    "                            decay_time, gSig, dims, dview = dview, \n",
    "                            min_SNR=min_SNR, r_values_min = r_values_min, min_std_reject = 0.5, use_cnn = False)\n",
    "\n",
    "print(' ***** ')\n",
    "print((len(cnm.C)))\n",
    "print((len(idx_components)))\n",
    "print(r_values[idx_components_bad])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot contours of selected and rejected components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% PLOT COMPONENTS\n",
    "\n",
    "plt.figure(figsize=(15,8));\n",
    "plt.subplot(121);\n",
    "crd = cm.utils.visualization.plot_contours(cnm.A.tocsc()[:,idx_components], cn_filter, thr=.8, vmax=0.95)\n",
    "plt.title('Contour plots of accepted components')\n",
    "plt.subplot(122); \n",
    "crd = cm.utils.visualization.plot_contours(cnm.A.tocsc()[:,idx_components_bad], cn_filter, thr=.8, vmax=0.95)\n",
    "plt.title('Contour plots of rejected components')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View traces of accepted and rejected components. Note that if you get data rate error you can start Jupyter notebooks using:\n",
    "'jupyter notebook --NotebookApp.iopub_data_rate_limit=1.0e10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accepted components\n",
    "nb_view_patches(Yr, cnm.A.tocsc()[:, idx_components], cnm.C[idx_components], \n",
    "                cnm.b, cnm.f, dims[0], dims[1], YrA=cnm.YrA[idx_components], image_neurons = cn_filter,\n",
    "                denoised_color = 'red', thr=0.8, cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rejected components\n",
    "nb_view_patches(Yr, cnm.A.tocsc()[:, idx_components_bad], cnm.C[idx_components_bad], \n",
    "                cnm.b, cnm.f, dims[0], dims[1], YrA=cnm.YrA[idx_components_bad], image_neurons = cn_filter,\n",
    "                denoised_color = 'red', thr=0.8, cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "cm.stop_server(dview=dview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some instructive movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% denoised movie\n",
    "cm.movie(np.reshape(cnm.A.tocsc()[:,idx_components].dot(cnm.C[idx_components])+cnm.b.dot(cnm.f),dims+(-1,), order = 'F').transpose(2,0,1)).play(magnification=3, gain = 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% only neurons\n",
    "cm.movie(np.reshape(cnm.A.tocsc()[:,idx_components].dot(cnm.C[idx_components]),dims+(-1,), order = 'F').transpose(2,0,1)).play(magnification=3, gain = 10.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% only the background\n",
    "cm.movie(np.reshape(cnm.b.dot(cnm.f),dims+(-1,), order = 'F').transpose(2,0,1)).play(magnification=3, gain = 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% residuals\n",
    "cm.movie(np.array(Y)-np.reshape(cnm.A.tocsc()[:,:].dot(cnm.C[:])+cnm.b.dot(cnm.f),dims+(-1,), order = 'F').transpose(2,0,1)).play(magnification=3, gain = 10., fr = 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% eventually, you can rerun the algorithm on the residuals\n",
    "plt.imshow(cm.movie(np.array(Y)-np.reshape(cnm.A.tocsc()[:,:].dot(cnm.C[:])+cnm.b.dot(cnm.f),dims+(-1,), order = 'F').transpose(2,0,1)).local_correlations(swap_dim=False))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
